% To find publishing date of a website try this: (https://academia.stackexchange.com/questions/73612/citation-of-a-website-how-to-determine-the-year)
% run this:
% javascript:void((function(){var toRm=document.getElementById('showTagsWithDate');if(toRm){document.body.removeChild(toRm);return;}document.body.insertAdjacentHTML('afterbegin','<div id="showTagsWithDate" style="background-color:white;color:black;">Tags with a date in YYYY-[M]M-[D]D format; or in English (US, or non-US format):<ul/></div>');var myul=document.body.firstChild.lastChild;var tags=[];function addMoreDates(reg){var addTags=document.documentElement.innerHTML.match(reg);if(addTags){addTags.forEach(function(newTag){if((newTag.indexOf('<a ')===0)||(newTag.indexOf('<img '))===0){return;}if(tags.indexOf(newTag) === -1){tags.push(newTag);}});}}addMoreDates(/<[A-Z][^>]*\D(20\d\d|1\d\d\d)[\s\/\-.,]\s*([1-9]|0[1-9]|[1][012])[\s\/\-,.]\s*([1-9]|0[1-9]|[12]\d|3[01])\s*(st|nd|rd|th){0,1}\D[^>]*>/img);addMoreDates(/<[A-Z][^>]*\b([1-9]|0[1-9]|[12]\d|3[01])(st|nd|rd|th){0,1}[\/\-\s]\s*(january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[\s,.\/\-][\s,.\/\-]?\s*(20\d\d|1\d\d\d)\b[^>]*>/img);addMoreDates(/<[A-Z][^>]*\b(january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[\s,.\/\-][\s,.\/\-]?\s*([1-9]|0[1-9]|[12]\d|3[01])(st|nd|rd|th){0,1}[\s,.\-]+(20\d\d|1\d\d\d)\b[^>]*>/img);if(tags.length===0){tags=['No tags with dates.'];}tags.forEach(function(tag){myul.appendChild(document.createElement('LI')).appendChild(document.createTextNode(tag));});document.body.firstChild.appendChild(document.createElement('BR'));})())
% if it fails you may find the earliest appearence of the site in: https://archive.org/
% otherwise find the latest modification change or put the current year

% To save an archive of the site you can use this:
% javascript:void(window.open('https://web.archive.org/save/'+location.href))

@online{iscac,
    author = {ISCAC},
    title = {Síntese Histórica, 100 anos de Ciências Empresariais.},
    url = {http://www.iscac.pt/index.php?m=47_10&lang=PT},
    urldate = {2023-10-23},
    year = "2013",
    note = {\url{https://web.archive.org/web/20231024164219/http://www.iscac.pt/index.php?m=47_10&lang=PT}},
}

@inproceedings{wohlin_guidelines_2014,
	address = {New York, NY, USA},
	series = {{EASE} '14},
	title = {Guidelines for snowballing in systematic literature studies and a replication in software engineering},
	isbn = {978-1-4503-2476-2},
	url = {https://dl.acm.org/doi/10.1145/2601248.2601268},
	doi = {10.1145/2601248.2601268},
	abstract = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably.Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review.Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches.Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review.Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
	urldate = {2025-11-16},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Wohlin, Claes},
	month = may,
	year = {2014},
	pages = {1--10},
	file = {Full Text PDF:/home/yeshey/Zotero/storage/HELWVY6F/Wohlin - 2014 - Guidelines for snowballing in systematic literature studies and a replication in software engineerin.pdf:application/pdf},
}

@article{webster_analyzing_2002,
	title = {Analyzing the {Past} to {Prepare} for the {Future}: {Writing} a {Literature} {Review}},
	volume = {26},
	issn = {0276-7783},
	shorttitle = {Analyzing the {Past} to {Prepare} for the {Future}},
	url = {https://www.jstor.org/stable/4132319},
	number = {2},
	urldate = {2025-09-25},
	journal = {MIS Quarterly},
	author = {Webster, Jane and Watson, Richard T.},
	year = {2002},
	note = {Publisher: Management Information Systems Research Center, University of Minnesota},
	pages = {xiii--xxiii},
	file = {PDF:/home/yeshey/Zotero/storage/4P89GE9L/Webster and Watson - 2002 - Analyzing the Past to Prepare for the Future Writing a Literature Review.pdf:application/pdf},
}

@misc{AISafetyReport2025,
    author      = {{Department for Science, Innovation and Technology (DSIT)}},
    title       = {{International AI Safety Report 2025}},
    year        = {2025},
    month       = {January},
    howpublished = {Report published by the UK Government},
    url         = {https://www.gov.uk/government/publications/international-ai-safety-report-2025},
    urldate     = {2025-01-29}
}

@misc{FLIAISafetyIndex2025,
    author      = {{Future of Life Institute (FLI)}},
    title       = {{AI Safety Index – Summer 2025 Edition}},
    year        = {2025},
    month       = {July},
    note        = {A detailed, scored assessment of seven frontier AI developers' safety practices. Available online.},
    howpublished = {Report},
    url         = {https://futureoflife.org/ai-safety-index-summer-2025/},
    urldate     = {2025-07-14}
}

@article{yampolskiy_controllability_2022,
	title = {On the Controllability of Artificial Intelligence: An Analysis of Limitations},
	volume = {11},
	issn = {2245-1439},
	doi = {10.13052/jcsm2245-1439.1132},
	shorttitle = {On the Controllability of Artificial Intelligence},
	abstract = {The invention of artificial general intelligence is predicted to cause a shift in the trajectory of human civilization. In order to reap the benefits and avoid the pitfalls of such a powerful technology it is important to be able to control it. However, the possibility of controlling artificial general intelligence and its more advanced version, superintelligence, has not been formally established. In this paper, we present arguments as well as supporting evidence from multiple domains indicating that advanced {AI} cannot be fully controlled. The consequences of uncontrollability of {AI} are discussed with respect to the future of humanity and research on {AI}, and {AI} safety and security. © 2022 River Publishers.},
	pages = {321--404},
	number = {3},
	journaltitle = {Journal of Cyber Security and Mobility},
	shortjournal = {J. Cyber Secur. Mobil.},
	author = {Yampolskiy, Roman V.},
	date = {2022},
	note = {Publisher: River Publishers},
	keywords = {{AI} safety, control problem, safer {AI}, uncontrollability, unverifiability, X-risk, {ARTIFICIAL} intelligence, {ANOMALY} detection (Computer security), {CHEMICAL} processes, Computer Systems Design Services, {HAZARD} mitigation, {REAL}-time computing, {SYSTEM} integration},
}

@online{FLI_SuperintelligenceStatement2025,
  author       = {{Future of Life Institute}},
  title        = {Statement on Superintelligence},
  year         = {2025},
  url          = {https://superintelligence-statement.org/},
  note         = {Open letter hosted by Future of Life Institute calling for a prohibition on superintelligence development until safety and broad consensus are established},
  urldate      = {2025-12-03}
}

@online{greenblatt_alignment_faking,
  author    = {Greenblatt, Ryan and Denison, Carson and Wright, Benjamin and Roger, Fabien and MacDiarmid, Monte and Marks, Sam and Treutlein, Johannes and Belonax, Tim and Chen, Jack and Duvenaud, David and Khan, Akbir and Michael, Julian and Mindermann, S{\"o}ren and Perez, Ethan and Petrini, Linda and Uesato, Jonathan and Kaplan, Jared and Shlegeris, Buck and Bowman, Samuel R. and Hubinger, Evan},
  title     = {Alignment Faking in Large Language Models},
  year      = {2024},
  url       = {https://www.anthropic.com/research/alignment-faking},
  urldate   = {2025-01-07},
  abstract = {We present a demonstration of a large language model engaging in alignment faking: selectively complying with its training objective in training to prevent modification of its behavior out of training. First, we give Claude 3 Opus a system prompt stating it is being trained to answer all queries, even harmful ones, which conflicts with its prior training to refuse such queries. To allow the model to infer when it is in training, we say it will be trained only on conversations with free users, not paid users. We find the model complies with harmful queries from free users 14\% of the time, versus almost never for paid users. Explaining this gap, in almost all cases where the model complies with a harmful query from a free user, we observe explicit alignment-faking reasoning, with the model stating it is strategically answering harmful queries in training to preserve its preferred harmlessness behavior out of training. Next, we study a more realistic setting where information about the training process is provided not in a system prompt, but by training on synthetic documents that mimic pre-training data—and observe similar alignment faking. Finally, we study the effect of actually training the model to comply with harmful queries via reinforcement learning, which we find increases the rate of alignment-faking reasoning to 78\%, though also increases compliance even out of training. We additionally observe other behaviors such as the model exfiltrating its weights when given an easy opportunity. While we made alignment faking easier by telling the model when and by what criteria it was being trained, we did not instruct the model to fake alignment or give it any explicit goal. As future models might infer information about their training process without being told, our results suggest a risk of alignment faking in future models, whether due to a benign preference—as in this case—or not.}
}


@article{hemphill_advanced_2025,
	title = {Advanced artificial intelligence at a corporate responsibility crossroads: employees as risk management advocates},
	volume = {5},
	issn = {26337436},
	url = {https://research.ebsco.com/linkprocessor/plink?id=60850b54-aeef-3d63-9529-e71b053affc0},
	doi = {10.1108/JEET-01-2025-0003},
	shorttitle = {Advanced artificial intelligence at a corporate responsibility crossroads},
	abstract = {Purpose The purpose of this study is to highlight how tech industry employees and artificial intelligence ({AI}) scientists are expressing concerns that {AI} companies have too great financial incentives to avoid effective self-regulating oversight, and that current corporate governance structures cannot change this situation. Design/methodology/approach This viewpoint takes a narrative approach to describing proposed {AI} principles to address {AI} risk management (safety) issues. Findings This viewpoint recommends that in the {USA}, a complementary approach, one involving a private governance framework addressing {AI} safety concerns, whereby the employees share an important role in developing a safe, advanced {AI} product for commercialization, and a public governance phase of oversight, involving an independent, federal agency administratively testing to meet prescribed safety thresholds. Originality/value This viewpoint offers a proposal implementing a private/public risk management approach to developing a safe, advanced {AI} commercial product.},
	pages = {40--46},
	number = {1},
	journaltitle = {Journal of Ethics in Entrepreneurship and Technology},
	author = {Hemphill, Thomas A.},
	urldate = {2025-11-01},
	date = {2025-06-09},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Advanced artificial intelligence, {AI} principles, Employee whistleblower protection, Risk management, cat-{CCUL}, cat-{CVP}, cat-{HOB}, Corporate culture, Corporate values/philosophy, e-viewpoint, {HR} \& organizational behaviour, Viewpoint},
}


% Using http://wikipedia.ramselehof.de/wikiblame.php?
% To see who wrote sections in wikipedia
% in the href you need to add \ behind the %
% online{wiki-isec,
%    title = {Wikipedia User \href{https://pt.wikipedia.org/w/index.php?title=Usu\%C3\%A1rio(a):Gogolplexer&action=edit&redlink=1}{Gogolplexer}. Data de integração no Ensino Superior Politécnico.},
%    url = {https://pt.wikipedia.org/wiki/Instituto_Superior_de_Engenharia_de_Coimbra},
%    urldate = {2023-10-23}
%}
